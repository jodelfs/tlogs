{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ac60615-3645-4df6-839b-a2f7e37a8c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dem_file = '/home/jens/daten/geometries/usgs_earth_explorer/merged_raster_100m.tif'\n",
    "\n",
    "T_selected = 50 # at 50 m depth\n",
    "sealing_selected = 'sealing_100'  # 100 m radiu\n",
    "#temp = 'T_50'\n",
    "\n",
    "dataset = 'RLP'\n",
    "#dataset = 'BW'\n",
    "\n",
    "logarithmic = False\n",
    "\n",
    "if dataset == 'BW':\n",
    "    intercept = 14.43\n",
    "    beta_elev = -.005\n",
    "    beta_seal = 0.\n",
    "\n",
    "    land_use_path = None\n",
    "    grid_sealing_area = None\n",
    "\n",
    "    regions_main = [\n",
    "        'odenwald',\n",
    "        'black_forest',\n",
    "        'swabian_alb',\n",
    "        'voralb',\n",
    "        'keuper_uplands',\n",
    "        'alpine_foothills',\n",
    "        'gaeu',\n",
    "        'upper_rhine_graben'\n",
    "    ]\n",
    "    \n",
    "    regions_path = '/home/jens/daten/geometries/geological_regions/BW/auswertungsregionen'    \n",
    "    state_boundary_path = \"/home/jens/daten/BW_temperatureLogs_shallow/geometries/Verw-Grenzen_ALKIS/Verwaltungsgrenzen_NOrA_Dez_2022_ALKIS-Shape/v_al_land.shp\"\n",
    "\n",
    "    vmin, vmax, vmin_res, vmax_res = 6, 15, -5, 5\n",
    "    gridx = np.arange(385000, 615000, 1000)\n",
    "    gridy = np.arange(5265000, 5525000, 1000)\n",
    "\n",
    "elif dataset == 'RLP':\n",
    "    land_use_path = \"/home/jens/daten/parameter/lbm-de2021.utm32s.shape/lbm-de2021/land/rp/lbm-de2021.shp\" # EPSG:25832\n",
    "    state_boundary_path = \"/home/jens/daten/RLP_temperatureLogs_shallow/geometries/RLP_boundary/landesgrenze_rlp.shp\"\n",
    "    intercept = 12.662277853596251\n",
    "    beta_elev = -0.008789\n",
    "    beta_seal = 0.012684\n",
    "\n",
    "    regions_main = []\n",
    "    if True:\n",
    "        regions_main = [\n",
    "            'rhine_graben_slab',\n",
    "            'rhine_graben_zwischenscholle',\n",
    "            'mainz_basin_tertiary',\n",
    "            'quaternary_north_west',\n",
    "            'quaternary_middle_rhine',\n",
    "            'tertiary_quaternary_rhine_main',\n",
    "            'palatinate_buntsandstein',\n",
    "            'palatinate_muschelkalk',\n",
    "            'triassic_north_west',\n",
    "            'tertiary_north_west',    \n",
    "            'palatinate_permokarbon',\n",
    "            'perm_nahe_prims_basin',\n",
    "            'palatinate_slate_mountain_range_south',\n",
    "            'palatinate_slate_mountain_range_north',\n",
    "            'lahn_dill',\n",
    "            'westerwald_tertiary',\n",
    "            'limestone_depression_buntsandstein_vulkanite',\n",
    "            'kaenozoic_vulkanite'   \n",
    "        ]\n",
    "    \n",
    "    regions_path = '/home/jens/daten/geometries/geological_regions/RLP/hydrogeology'\n",
    "\n",
    "    # Total RLP\n",
    "    #vmin, vmax, vmin_res, vmax_res = 6, 15, -5, 5\n",
    "    #grid_sealing_area = 1000*1000    \n",
    "    #gridx = np.arange(290000, 475000, 1000)\n",
    "    #gridy = np.arange(5420000, 5650000, 1000)\n",
    "        \n",
    "    # Ramstein\n",
    "    vmin, vmax, vmin_res, vmax_res = 8, 12, -1, 1\n",
    "    grid_sealing_area = 100*100\n",
    "    gridx = np.arange(392100, 404800, 100)\n",
    "    gridy = np.arange(5469600, 5482300, 100)\n",
    "\n",
    "\n",
    "def trend_global(_elev, _seal):\n",
    "    return intercept + beta_elev*_elev + beta_seal*_seal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9abee13-e738-4285-8186-e72beb0e1e3e",
   "metadata": {},
   "source": [
    "<h1> Import </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd2f3e6-75b1-4d9e-91d4-e9ada041fb1b",
   "metadata": {},
   "source": [
    "<h2> Modules </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "932a68f4-2922-4baf-b00d-971f6f18b35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import gstools as gs\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import rasterio\n",
    "from rasterio.warp import reproject, Resampling, calculate_default_transform\n",
    "import geopandas as gpd\n",
    "from pyproj import Transformer\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.models import LinearColorMapper, ColorBar, HoverTool, ColumnDataSource, Range1d, LinearAxis, GeoJSONDataSource, Label\n",
    "from bokeh.transform import linear_cmap, cumsum\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.resources import INLINE\n",
    "from bokeh.palettes import Reds256, Oranges256, Blues256, Greens256, RdBu, YlGn, RdYlGn, linear_palette, YlOrBr, Viridis256\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072810a5-a0c6-4e36-bf79-7cf0bcd6acf0",
   "metadata": {},
   "source": [
    "<h2> DEM </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4ddd43-a2ea-4a77-818e-f6ef73203bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16129 Points\n",
      "\tPoint 0\n",
      "\tPoint 1000\n",
      "\tPoint 2000\n",
      "\tPoint 3000\n",
      "\tPoint 4000\n"
     ]
    }
   ],
   "source": [
    "src = rasterio.open(dem_file)\n",
    "\n",
    "xx, yy = np.meshgrid(gridx, gridy)\n",
    "\n",
    "transformer = Transformer.from_crs(\"EPSG:32632\", \"EPSG:4326\", always_xy=True)\n",
    "_xx, _yy =  transformer.transform(xx, yy)\n",
    "\n",
    "gdf_points = gpd.GeoDataFrame(geometry=gpd.points_from_xy(_xx.flatten(), _yy.flatten()) )\n",
    "gdf_points.crs=\"EPSG:4326\"\n",
    "gdf_points = gdf_points.to_crs(src.crs)\n",
    "\n",
    "grid_elevation_values = np.zeros(_xx.size)\n",
    "\n",
    "print(f'{xx.size} Points')\n",
    "for ndx, point in enumerate(gdf_points.geometry):\n",
    "    if ndx%1000 == 0:\n",
    "        print(f'\\tPoint {ndx}')\n",
    "    x, y = point.x, point.y\n",
    "    row, col = src.index(x, y)\n",
    "    #elevation = np.flipud(src.read(1))[row, col]\n",
    "    #elevation = src.read(1).T[row, col]\n",
    "    elevation = src.read(1)[row, col] # 200\n",
    "    grid_elevation_values[ndx] = elevation\n",
    "\n",
    "######\n",
    "dst_crs = \"EPSG:32632\"\n",
    "\n",
    "#grid_elevation_values = grid_elevation_values.T\n",
    "#grid_elevation_values = np.flipud(grid_elevation_values)\n",
    "\n",
    "# Berechne Transformation und neue Dimensionen\n",
    "transform, width, height = calculate_default_transform(src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
    "\n",
    "# Initialisiere ein Array für die transformierten Daten\n",
    "transformed_dem = np.empty((height, width), dtype=src.meta['dtype'])\n",
    "\n",
    "# Transformiere das Raster\n",
    "reproject(\n",
    "    source=src.read(1),\n",
    "    destination=transformed_dem,\n",
    "    src_transform=src.transform,\n",
    "    src_crs=src.crs,\n",
    "    dst_transform=transform,\n",
    "    dst_crs=dst_crs,\n",
    "    resampling=Resampling.nearest\n",
    ")\n",
    "\n",
    "dem_extent = [transform[2], transform[2] + width * transform[0], transform[5] + height * transform[4], transform[5]]\n",
    "\n",
    "grid_elevation_values = grid_elevation_values.reshape(xx.shape).T\n",
    "\n",
    "#grid_elevation_values = np.ones_like(grid_elevation_values) * 250\n",
    "\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce89133f-dc32-4a04-a2b2-bbd3ed219ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sealing_on_grid(gridx, gridy, gdf_versiegelung, radius, value_column='SIE_AKT'):\n",
    "    \"\"\"\n",
    "    Berechnet den gewichteten Versiegelungsgrad für jeden Punkt eines regulären Grids.\n",
    "\n",
    "    Parameter:\n",
    "    -----------\n",
    "    gridx, gridy : 1D numpy arrays\n",
    "        Koordinaten des Rasters (in EPSG:32632).\n",
    "    gdf_versiegelung : GeoDataFrame\n",
    "        Polygone mit Versiegelungswerten (z. B. Bodenversiegelung), CRS = EPSG:32632.\n",
    "    radius : float\n",
    "        Suchradius in Metern.\n",
    "    value_column : str\n",
    "        Name der Spalte im Polygon-Layer mit Versiegelungsgrad (0–100 oder 0–1).\n",
    "\n",
    "    Rückgabe:\n",
    "    ----------\n",
    "    grid_sealing_values : 2D numpy array (shape = (len(gridy), len(gridx)))\n",
    "        Gitter mit gewichteten Versiegelungswerten.\n",
    "    \"\"\"\n",
    "\n",
    "    # Meshgrid für alle Punkte\n",
    "    xx, yy = np.meshgrid(gridx, gridy)\n",
    "    flat_points = np.column_stack([xx.flatten(), yy.flatten()])\n",
    "\n",
    "    print(f\"{flat_points.shape[0]} grid points → buffering radius {radius:.1f} m\")\n",
    "\n",
    "    # GeoDataFrame aus Gitterpunkten\n",
    "    gdf_points = gpd.GeoDataFrame(\n",
    "        geometry=gpd.points_from_xy(flat_points[:,0], flat_points[:,1]),\n",
    "        crs=\"EPSG:32632\"\n",
    "    )\n",
    "\n",
    "    # Buffer um jeden Gitterpunkt\n",
    "    gdf_buffer = gdf_points.copy()\n",
    "    gdf_buffer[\"geometry\"] = gdf_buffer.buffer(radius)\n",
    "    gdf_buffer[\"grid_index\"] = gdf_buffer.index\n",
    "\n",
    "    # Overlay mit Versiegelungspolygonen\n",
    "    intersection = gpd.overlay(gdf_buffer, gdf_versiegelung, how=\"intersection\")\n",
    "    print(f\"Overlay intersections: {len(intersection)}\")\n",
    "\n",
    "    if intersection.empty:\n",
    "        print(\"No intersections – all sealing values set to 0\")\n",
    "        return np.zeros(xx.shape)\n",
    "\n",
    "    # Flächenberechnung\n",
    "    intersection[\"area\"] = intersection.geometry.area\n",
    "\n",
    "    # Gewichtete Versiegelung pro Rasterzelle\n",
    "    def weighted_sealing(gr):\n",
    "        total_area = gr[\"area\"].sum()\n",
    "        if total_area == 0:\n",
    "            return 0.0\n",
    "        return (gr[value_column] * gr[\"area\"]).sum() / total_area\n",
    "\n",
    "    sealing_series = (\n",
    "    intersection.drop(columns=[\"grid_index\"])\n",
    "    .groupby(intersection[\"grid_index\"])\n",
    "    .apply(weighted_sealing))\n",
    "\n",
    "    # Ergebnisse wieder in Gitterform bringen\n",
    "    grid_sealing_values = sealing_series.reindex(\n",
    "        range(flat_points.shape[0]), fill_value=np.nan\n",
    "    ).to_numpy().reshape(xx.shape)\n",
    "\n",
    "    print(\"Finished computing sealing grid.\")\n",
    "    return grid_sealing_values\n",
    "\n",
    "\n",
    "if dataset == 'RLP':\n",
    "    grid_sealing_radius = np.sqrt(grid_sealing_area / 3.14150)\n",
    "    print('grid_sealing_radius: ', grid_sealing_radius)\n",
    "\n",
    "    radius= grid_sealing_radius#np.sqrt(area_selected*area_selected / np.pi)\n",
    "    \n",
    "    # Lade Versiegelungsdaten und projiziere richtig\n",
    "    gdf_versiegelung = gpd.read_file(land_use_path)\n",
    "    gdf_versiegelung = gdf_versiegelung.to_crs(\"EPSG:32632\")\n",
    "    \n",
    "    grid_sealing_values = calculate_sealing_on_grid(gridx, gridy, gdf_versiegelung, radius, value_column='SIE_AKT')\n",
    "    \n",
    "    grid_sealing_values = np.nan_to_num(grid_sealing_values, nan=0.0)\n",
    "    #grid_sealing_values = np.zeros_like(grid_sealing_values)\n",
    "    \n",
    "    grid_sealing_values = grid_sealing_values.reshape(xx.shape).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3f6f99-7e4c-49db-af8d-89b658b6710a",
   "metadata": {},
   "source": [
    "<h2> Borehole data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bea59ea-a435-4c74-b58a-dfc7fe67ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'BW':\n",
    "    user, password ='postgres', 'postgres'\n",
    "    schema, host = 'DB_BW_temperature_shallow', '127.0.0.1'\n",
    "    connection_string='postgresql://{}:{}@{}:5432/{}'.format(user, password, host, schema)\n",
    "    \n",
    "    engine = create_engine(connection_string)\n",
    "    \n",
    "    df = pd.read_sql_query(\"SELECT * FROM temperatures_approximation;\", engine)\n",
    "    df_bh_evaluation = pd.read_sql_query(\"SELECT * FROM borehole_evaluation;\", engine)\n",
    "    df_infos = pd.read_sql_query(\"SELECT * FROM log_infos;\", engine)\n",
    "    \n",
    "    df = pd.merge(df, df_bh_evaluation[\n",
    "                  ['borehole_id', 'date', 'drillingInduced', 'deactivated', 'quality']], \n",
    "                  on='borehole_id', how='inner')\n",
    "    \n",
    "    \n",
    "    df = df.merge(df_infos[['borehole_id', 'utm_easting', 'utm_northing', \n",
    "                                'elevation', 'sample_id', 'land_use', 'N112', 'N120', 'N211', 'N311']], on='borehole_id', how='left')\n",
    "    \n",
    "    df = df[df['sample_id'] == 'a']\n",
    "    \n",
    "    df = df.drop_duplicates()\n",
    "    df[sealing_selected] = 0\n",
    "\n",
    "elif dataset == 'RLP': # for sealing at wells\n",
    "    df = pd.read_csv('df4statstools.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f28a3b-61ae-4225-bcc3-e3adbeb8d16d",
   "metadata": {},
   "source": [
    "<h2> Filter </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f793913-334e-4322-82d4-96c422a84350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter\n",
    "print(f'Wells: {df.shape[0]}')\n",
    "\n",
    "\n",
    "df_filt = df[~df['borehole_id'].astype(str).str.startswith('GT')]\n",
    "print(f'After removed deppe wells from GeotIS: {df_filt.shape[0]}')\n",
    "\n",
    "df_filt = df_filt[df_filt['drillingInduced'] == False]\n",
    "print(f'After removed wells impacted by drilling: {df_filt.shape[0]}')\n",
    "df_filt = df_filt[df_filt['deactivated'] == False]\n",
    "print(f'After removed deactivated wells: {df_filt.shape[0]}')\n",
    "\n",
    "df_filt = df_filt.dropna(subset=[f\"T_{T_selected}\"])\n",
    "\n",
    "print(f'And at depth {T_selected}: {df_filt.shape[0]}')\n",
    "\n",
    "\n",
    "if dataset == 'RLP':\n",
    "    df_filt = df_filt[df_filt[\"quality\"] > -1 ]\n",
    "    print(f'After removed quality < 0: {df_filt.shape[0]}')\n",
    "\n",
    "\n",
    "#print(df_cleaned.shape[0], \" boreholes\")\n",
    "\n",
    "# for variogram\n",
    "factor = 2.5 # um ausreisser im variogram zu entfernen\n",
    "\n",
    "q1, q3 = np.percentile(df_filt[f\"T_{T_selected}\"].to_numpy(), [25, 75])\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - factor * iqr\n",
    "upper_bound = q3 + factor * iqr\n",
    "\n",
    "\n",
    "df_filt_cleaned = df_filt[(df_filt[f\"T_{T_selected}\"]>lower_bound)&(df_filt[f\"T_{T_selected}\"]<upper_bound) ]\n",
    "\n",
    "print(df_filt_cleaned.shape[0], f\" boreholes after cleaning (factor {factor}) with bounds: {lower_bound} {upper_bound}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdc0fbf-cfef-42ed-af85-760c23108cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_main = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86284974-15fd-4e4f-9d05-557d08dcc6ef",
   "metadata": {},
   "source": [
    "<h2> Plot funktions </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d1dc7f-bc34-4dc5-8499-e94f7595fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variogram(title, fit_model, bin_center, gamma, bin_counts, para, r2):\n",
    "    bin_center = np.insert(bin_center, 0, para['nugget']) # to get position zero in plot \n",
    "    source = ColumnDataSource(data={'lags': bin_center/1000, \n",
    "                                    'semi_variances': gamma, \n",
    "                                    'model_values': fit_model.variogram(bin_center), \n",
    "                                    'bin_counts': bin_counts})\n",
    "    \n",
    "    semi_variances_max = max(max(gamma), max(fit_model.variogram(bin_center)))*1.1\n",
    "    \n",
    "    p = figure(title='',#'range {:.0f}, sill {:.1f}, nugget {:.1f}, Pseudo-R² {:.3f}'.format(\n",
    "        #para['len_scale'], para['var'], para['nugget'], r2), \n",
    "                           x_axis_label='Lag-distance [km]', y_axis_label='Semivariance [K²]', \n",
    "                           width=500, height=300, \n",
    "                           y_range=Range1d(start=0, end=semi_variances_max))\n",
    "    \n",
    "    p.scatter('lags', 'semi_variances', size=8, color='blue', #legend_label='Experimental', \n",
    "                     source=source)\n",
    "    p.line('lags', 'model_values', line_width=2, color='red', #legend_label='Spherical', \n",
    "                   source=source)\n",
    "    #\n",
    "    p.extra_y_ranges['bin_count_range'] =  Range1d(start=0, end=max(bin_counts)*1.1)\n",
    "    \n",
    "    ax2 = LinearAxis(axis_label='N', y_range_name='bin_count_range')\n",
    "    p.add_layout(ax2, 'right')\n",
    "\n",
    "    if \"var\" in para:\n",
    "        text = Label(x=260, y=35,#  38, \n",
    "                     x_units='screen', y_units='screen',\n",
    "                     #text='\\n Range: {:.0f} \\n Sill: {:.1f} \\n Pseudo-R²: {:.3f} \\n'.format(\n",
    "                     #    para['len_scale'], para['var'], r2),\n",
    "                     text='\\n Range: {:.0f} \\n Sill: {:.1f} \\n Nugget: {:.1f} \\n Pseudo-R²: {:.3f} \\n'.format(\n",
    "                         para['len_scale'], para['var'], para['nugget'], r2),\n",
    "                     text_font_size='8pt',\n",
    "                     text_baseline=\"middle\", text_align=\"left\",\n",
    "                     background_fill_color='white', background_fill_alpha=1)\n",
    "    else: # double variogram\n",
    "        if para['var2'] == 0:\n",
    "            text = Label(x=260, y=35,#  38, \n",
    "                     x_units='screen', y_units='screen',\n",
    "                     #text='\\n Range: {:.0f} \\n Sill: {:.1f} \\n Pseudo-R²: {:.3f} \\n'.format(\n",
    "                     #    para['len_scale'], para['var'], r2),\n",
    "                    text='\\n Range: {:.0f} \\n    Sill: {:.1f} \\n Nugget: {:.1f} \\n\\n Pseudo-R²: {:.3f} \\n'.format(\n",
    "                     para['len_scale1'], para['var1'], para['nugget'], r2),\n",
    "                    text_font_size='8pt',\n",
    "                    text_baseline=\"middle\", text_align=\"left\",\n",
    "                    background_fill_color='white', background_fill_alpha=1) \n",
    "        else:\n",
    "            text = Label(x=260, y=70,#  38, \n",
    "                         x_units='screen', y_units='screen',\n",
    "                         #text='\\n Range: {:.0f} \\n Sill: {:.1f} \\n Pseudo-R²: {:.3f} \\n'.format(\n",
    "                         #    para['len_scale'], para['var'], r2),\n",
    "                        text='\\n Near-Field\\n    Range: {:.0f} \\n    Sill: {:.1f} \\n Far-Field\\n    Range: {:.0f} \\n    Sill: {:.1f} \\n Nugget: {:.1f} \\n\\n Pseudo-R²: {:.3f} \\n'.format(\n",
    "                         para['len_scale1'], para['var1'], para['len_scale2'], para['var2'], para['nugget'], r2),\n",
    "                        text_font_size='8pt',\n",
    "                        text_baseline=\"middle\", text_align=\"left\",\n",
    "                        background_fill_color='white', background_fill_alpha=1)    \n",
    "    p.add_layout(text)\n",
    "    \n",
    "    p.vbar(x='lags', top='bin_counts', width=.9, \n",
    "                       color='black', alpha=.5, \n",
    "           y_range_name='bin_count_range', source=source)\n",
    "\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04057ff-6d98-4266-b523-1b66acf90b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_temp(srf, vmin=6, vmax=16):\n",
    "    fig, axes = plt.subplots()#1, 1, figsize=(20, 5))\n",
    "        \n",
    "    ax = axes\n",
    "    im = ax.imshow(srf.T, origin=\"lower\", cmap='coolwarm', vmin=vmin, vmax=vmax, \n",
    "                   extent=(gridx.min(), gridx.max(), gridy.min(), gridy.max()))\n",
    "    \n",
    "    cbar = plt.colorbar(im, ax=ax, #orientation=\"horizontal\", \n",
    "                        #ticks=boundaries\n",
    "                       )\n",
    "    cbar.set_label(\"Temperature (°C)\")\n",
    "    \n",
    "    ax.scatter(bhs_x, bhs_y, color='k', zorder=10, marker='+', label='Conditions')\n",
    "    ax.set_xlim([gridx.min(), gridx.max()])\n",
    "    ax.set_ylim([gridy.min(), gridy.max()])\n",
    "\n",
    "def plot_std(var):\n",
    "    fig, axes = plt.subplots()#1, 1, figsize=(20, 5))\n",
    "        \n",
    "    ax = axes\n",
    "    std = np.sqrt(var.T)\n",
    "    \n",
    "    boundaries = np.arange(0, np.ceil(std.max()),# + 0.5, \n",
    "                               0.5)\n",
    "        \n",
    "    # Normierung: sorgt für harte Übergänge\n",
    "    norm = mcolors.BoundaryNorm(boundaries=boundaries, ncolors=plt.cm.viridis.N)\n",
    "    \n",
    "    im = ax.imshow(std, origin=\"lower\", cmap='viridis', extent=(gridx.min(), gridx.max(), gridy.min(), gridy.max()),\n",
    "             #vmin=0, vmax=3, \n",
    "              norm=norm)\n",
    "    \n",
    "    cbar = plt.colorbar(im, ax=ax, #orientation=\"horizontal\", \n",
    "                        ticks=boundaries)\n",
    "    cbar.set_label(\"Kriging Standardabweichung (σ)\")\n",
    "    \n",
    "    ax.scatter(bhs_x, bhs_y, color='k', zorder=10, marker='+', label='Conditions')\n",
    "    ax.set_xlim([gridx.min(), gridx.max()])\n",
    "    ax.set_ylim([gridy.min(), gridy.max()])\n",
    "\n",
    "def plot_dem(xx, yy, grid_elevation_values):\n",
    "\n",
    "    fig, axes = plt.subplots()#1, 1, figsize=(20, 5))\n",
    "    \n",
    "    ax = axes\n",
    "    c = ax.pcolormesh(xx, yy, grid_elevation_values.T, cmap=\"terrain\", shading=\"auto\")\n",
    "    fig.colorbar(c, ax=ax, label=\"Elevation [m]\")\n",
    "    ax.scatter(bhs_x, bhs_y, color='k', zorder=10, marker='+', label='Conditions')\n",
    "    ax.set_xlim([gridx.min(), gridx.max()])\n",
    "    ax.set_ylim([gridy.min(), gridy.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889e678f-44ae-456b-b4e1-d2b8bf692a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dem(path, x_offset, y_offset):\n",
    "    with rasterio.open(path) as src:\n",
    "        dem = src.read(1)  # first band\n",
    "        dem = np.where(dem == src.nodata, np.nan, dem)  # mask nodata values\n",
    "        bounds = src.bounds\n",
    "        \n",
    "        # convert to km relative to offset\n",
    "        x_min = (bounds.left - x_offset) / 1000\n",
    "        x_max = (bounds.right - x_offset) / 1000\n",
    "        y_min = (bounds.bottom - y_offset) / 1000\n",
    "        y_max = (bounds.top - y_offset) / 1000\n",
    "        \n",
    "        dw = x_max - x_min\n",
    "        dh = y_max - y_min\n",
    "        \n",
    "    return dem, x_min, y_min, dw, dh\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af9a6f9-b7da-4124-85da-b6e5a0e16688",
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_ratio = (gridy.max() - gridy.min()) /(gridx.max()-gridx.min())\n",
    "\n",
    "def do_T_plot(cbar_title, _srf, x_min, x_max, y_min, y_max, x_range, y_range, tooltips, \n",
    "              source, temp_difference=False, logarithmic=False):\n",
    "    p = figure(\n",
    "        #title=title,\n",
    "        x_range=x_range,\n",
    "        y_range=y_range,\n",
    "        width=500,\n",
    "        height=int(500 * aspect_ratio),\n",
    "        tooltips=tooltips,\n",
    "        match_aspect=True\n",
    "    )\n",
    "\n",
    "    if temp_difference: # residuals\n",
    "        if vmax-vmin < 3:\n",
    "            color_mapper_field = LinearColorMapper(palette=RdBu[(vmax-vmin)*4], low=vmin_res, high=vmax_res)\n",
    "        else:\n",
    "            color_mapper_field = LinearColorMapper(palette=RdBu[(vmax-vmin)], low=vmin_res, high=vmax_res)\n",
    "        color_bar = ColorBar(\n",
    "            color_mapper=color_mapper_field, \n",
    "            location=(0, 0), \n",
    "            title=cbar_title,\n",
    "            orientation='horizontal'\n",
    "        )\n",
    "    else:\n",
    "        if vmax-vmin < 5:\n",
    "            color_mapper_field = LinearColorMapper(palette=RdBu[(vmax-vmin)*2], low=vmin, high=vmax)\n",
    "        else:\n",
    "            color_mapper_field = LinearColorMapper(palette=RdBu[(vmax-vmin)], low=vmin, high=vmax)\n",
    "        # ColorBar mit Titel \"Temperatur [°C]\" (fett) und Ticks fett\n",
    "        color_bar = ColorBar(\n",
    "            color_mapper=color_mapper_field, \n",
    "            location=(0, 0), \n",
    "            title=cbar_title,\n",
    "            orientation='horizontal'\n",
    "        )\n",
    "    \n",
    "    p.xaxis.axis_label = \"UTM Easting [km]\"\n",
    "    p.yaxis.axis_label = \"UTM Northing [km]\"\n",
    "    p.xaxis.axis_label_text_font_style = \"bold\"\n",
    "    p.yaxis.axis_label_text_font_style = \"bold\"\n",
    "    p.xaxis.major_label_text_font_style = \"bold\"\n",
    "    p.yaxis.major_label_text_font_style = \"bold\"\n",
    "    p.title.text_font_size = \"10pt\"\n",
    "    p.xaxis.axis_label_text_font_size = \"12pt\"\n",
    "    p.yaxis.axis_label_text_font_size = \"12pt\"\n",
    "\n",
    "    field = np.exp(_srf.T) if logarithmic else _srf.T\n",
    "    \n",
    "    p.image(\n",
    "        image=[field],\n",
    "        #x=0,  # entspricht (x_min - x_offset)/1000 = 0 km\n",
    "        #y=0,  # entspricht 0 km\n",
    "        x=x_min/1000, y=y_min/1000, # !!\n",
    "        dw=(x_max - x_min) / 1000,\n",
    "        dh=(y_max - y_min) / 1000,\n",
    "        color_mapper=color_mapper_field,\n",
    "        level=\"image\"\n",
    "    )\n",
    "\n",
    "    color_bar.major_label_text_font_size = \"12pt\"\n",
    "    color_bar.major_label_text_font_style = \"bold\"\n",
    "    color_bar.title_text_font_size = \"12pt\"\n",
    "    color_bar.title_text_font_style = \"bold\"\n",
    "    p.add_layout(color_bar, 'below')\n",
    "    \n",
    "    p.scatter(\n",
    "        'x',\n",
    "        'y',\n",
    "        size=10,\n",
    "        color='black',\n",
    "        marker='cross',\n",
    "        source=source\n",
    "    )\n",
    "     \n",
    "    p.xaxis.major_label_text_font_size = \"12pt\"\n",
    "    p.yaxis.major_label_text_font_size = \"12pt\"\n",
    "    p.xaxis.axis_label = \"UTM Easting [km]\"\n",
    "    p.yaxis.axis_label = \"UTM Northing [km]\"\n",
    "    p.xaxis.axis_label_text_font_style = \"bold\"\n",
    "    p.yaxis.axis_label_text_font_style = \"bold\"\n",
    "    p.xaxis.major_label_text_font_style = \"bold\"\n",
    "    p.yaxis.major_label_text_font_style = \"bold\"\n",
    "    p.title.text_font_size = \"10pt\"\n",
    "    p.xaxis.axis_label_text_font_size = \"12pt\"\n",
    "    p.yaxis.axis_label_text_font_size = \"12pt\"\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724db6f2-8c5f-4e66-af2b-10a5a7a12eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_bplot(title, _dem_file, dem_lim, grids, \n",
    "             srf, var, df, df_cleaned, bhs_x, bhs_y, bhs_val, grid_drift=None, logarithmic=False):\n",
    "    #\n",
    "    p = [[None] * 3 for _ in range(2)] \n",
    "    \n",
    "    x_min = grids[0].min() # df[df['T_0'].notna()]['utm_easting'].to_numpy().min() #- 40000\n",
    "    x_max = grids[0].max() # df[df['T_0'].notna()]['utm_easting'].to_numpy().max() #+ 15000\n",
    "    y_min = grids[1].min() # df[df['T_0'].notna()]['utm_northing'].to_numpy().min() #- 20000\n",
    "    y_max = grids[1].max() # df[df['T_0'].notna()]['utm_northing'].to_numpy().max() #+ 30000\n",
    "    \n",
    "    # Offsets: linke untere Ecke (in Meter) -> entspricht 0 km, 0 km\n",
    "    x_offset = 0.#x_min # !!\n",
    "    y_offset = 0.#y_min # !!\n",
    "    \n",
    "    # Neue Grenzen in km\n",
    "    #x_range_km = (0, (x_max - x_min) / 1000)\n",
    "    #y_range_km = (0, (y_max - y_min) / 1000)\n",
    "    x_range_km = (x_min / 1000, x_max / 1000) # !!\n",
    "    y_range_km = (y_min / 1000, y_max / 1000) # !!\n",
    "\n",
    "\n",
    "    # Für alle Plots dieselben Achsen (in km)\n",
    "    x_range = x_range_km\n",
    "    y_range = y_range_km\n",
    "    \n",
    "    \n",
    "    color_mapper_error = LinearColorMapper(palette=linear_palette(YlOrBr[4][::-1], 4), low=0, high=2) \n",
    "    \n",
    "    data = dict(\n",
    "        x = ((bhs_x- x_offset) / 1000), \n",
    "        y = ((bhs_y - y_offset) / 1000), \n",
    "        z = bhs_val,\n",
    "        bh_id = df_cleaned['borehole_id'].to_numpy(),\n",
    "        quality = df_cleaned['quality'].to_numpy(),\n",
    "        drillingInduced = df_cleaned['drillingInduced'].to_numpy()\n",
    "    )\n",
    "    source = ColumnDataSource(data)\n",
    "    \n",
    "    tooltips = [(\"ID:\", \"@bh_id\"),\n",
    "                (\"T [°C]:\", \"@z\"),\n",
    "                (\"Quality:\", \"@quality (@drillingInduced)\")]\n",
    "    \n",
    "    # Temperaturfeld ----\n",
    "    p[0][0] = do_T_plot(\"Temperature [°C]\", srf, x_min, x_max, y_min, y_max, x_range, y_range, tooltips, source, logarithmic=logarithmic)\n",
    "    \n",
    "    if grid_drift is not None:\n",
    "        p[1][0] = do_T_plot(\"Drift model [°C]\", \n",
    "                            grid_drift, x_min, x_max, y_min, y_max, p[0][0].x_range, p[0][0].y_range, \n",
    "                            tooltips, source, logarithmic=logarithmic)\n",
    "        p[1][1] = do_T_plot(\"Residuals [K]\", \n",
    "                            srf-grid_drift, x_min, x_max, y_min, y_max, p[0][0].x_range, \n",
    "                            p[0][0].y_range, tooltips, source,\n",
    "                            temp_difference=True, logarithmic=logarithmic)\n",
    "        \n",
    "    # ---- Kriging Error ----\n",
    "    p[0][1] = figure(\n",
    "        title=title,#\"{}, Kriging error\".format(title[temp]),\n",
    "        x_range=p[0][0].x_range,\n",
    "        y_range=p[0][0].y_range,\n",
    "        width=500,\n",
    "        height=int(500 * aspect_ratio),\n",
    "        match_aspect=True\n",
    "    )\n",
    "    \n",
    "    p[0][1].xaxis.axis_label = \"UTM Easting [km]\"\n",
    "    p[0][1].yaxis.axis_label = \"UTM Northing [km]\"\n",
    "    p[0][1].xaxis.axis_label_text_font_style = \"bold\"\n",
    "    p[0][1].yaxis.axis_label_text_font_style = \"bold\"\n",
    "    p[0][1].xaxis.major_label_text_font_style = \"bold\"\n",
    "    p[0][1].yaxis.major_label_text_font_style = \"bold\"\n",
    "    p[0][1].title.text_font_size = \"10pt\"\n",
    "    p[0][1].xaxis.axis_label_text_font_size = \"12pt\"\n",
    "    p[0][1].yaxis.axis_label_text_font_size = \"12pt\"\n",
    "\n",
    "    p[0][1].image(\n",
    "        image=[np.sqrt(var.T)],  # Standardabweichung\n",
    "        #x=0,\n",
    "        #y=0,\n",
    "        x=x_min/1000, y=y_min/1000, # !!\n",
    "        dw=(x_max - x_min) / 1000,\n",
    "        dh=(y_max - y_min) / 1000,\n",
    "        color_mapper=color_mapper_error\n",
    "\n",
    "   )\n",
    "    \n",
    "    color_bar_error = ColorBar(\n",
    "        color_mapper=color_mapper_error, \n",
    "        location=(0, 0), \n",
    "        title=\"Kriging standard deviation [K]\", \n",
    "        orientation='horizontal'\n",
    "    )\n",
    "    color_bar_error.major_label_text_font_size = \"12pt\"\n",
    "    color_bar_error.major_label_text_font_style = \"bold\"\n",
    "    color_bar_error.title_text_font_size = \"12pt\"\n",
    "    color_bar_error.title_text_font_style = \"bold\"\n",
    "    p[0][1].add_layout(color_bar_error, 'below')\n",
    "    #p[0][1].patches(xs, ys, fill_alpha=0, line_width=3, line_color=\"green\")\n",
    "\n",
    "    scattersize = 3\n",
    "    p[0][1].scatter(\n",
    "        ((df_cleaned['utm_easting'].to_numpy() - x_offset) / 1000), \n",
    "        ((df_cleaned['utm_northing'].to_numpy() - y_offset) / 1000), \n",
    "        size=scattersize, color='green', marker='circle'\n",
    "    )\n",
    "\n",
    "    p[0][1].xaxis.major_label_text_font_size = \"12pt\"\n",
    "    p[0][1].yaxis.major_label_text_font_size = \"12pt\"\n",
    "\n",
    "\n",
    "    ###########\n",
    "    # DEM\n",
    "\n",
    "    dem_array, dem_x, dem_y, dem_dw, dem_dh = load_dem(_dem_file, x_offset, y_offset)\n",
    "\n",
    "    color_mapper_dem = LinearColorMapper(palette=RdYlGn[int(dem_lim[1]-dem_lim[0]) / 100], \n",
    "                                         low=dem_lim[0], high=dem_lim[1])\n",
    "\n",
    "    p[0][2] = figure(\n",
    "        x_range=p[0][0].x_range,\n",
    "        y_range=p[0][0].y_range,\n",
    "        width=500,\n",
    "        height=int(500 * aspect_ratio),\n",
    "        match_aspect=True\n",
    "    )\n",
    "\n",
    "    p[0][2].image(\n",
    "        image=[np.flipud(dem_array)],  # rasterio reads top->bottom, flip for correct orientation\n",
    "        #x=0,\n",
    "        #y=0,\n",
    "        #dw=(x_max - x_min) / 1000,\n",
    "        #dh=(y_max - y_min) / 1000,\n",
    "        x=dem_x,\n",
    "        y=dem_y,\n",
    "        dw=dem_dw,\n",
    "        dh=dem_dh,\n",
    "        color_mapper=color_mapper_dem\n",
    "    )\n",
    "\n",
    "    color_bar_dem = ColorBar(\n",
    "        color_mapper=color_mapper_dem,\n",
    "        location=(0, 0),\n",
    "        title=\"Land surface elevation [m]\",\n",
    "        orientation=\"horizontal\"\n",
    "    )\n",
    "\n",
    "    color_bar_dem.major_label_text_font_size = \"12pt\"\n",
    "    color_bar_dem.major_label_text_font_style = \"bold\"\n",
    "    color_bar_dem.title_text_font_size = \"12pt\"\n",
    "    color_bar_dem.title_text_font_style = \"bold\"\n",
    "    p[0][2].add_layout(color_bar_dem, 'below')\n",
    "\n",
    "    p[0][2].scatter(\n",
    "        'x',\n",
    "        'y',\n",
    "        size=10,\n",
    "        color='black',\n",
    "        marker='cross',\n",
    "        source=source\n",
    "    )\n",
    "     \n",
    "    p[0][2].xaxis.major_label_text_font_size = \"12pt\"\n",
    "    p[0][2].yaxis.major_label_text_font_size = \"12pt\"\n",
    "\n",
    "    # Achsenbeschriftungen in km (fett) und Ticks fett\n",
    "    p[0][2].xaxis.axis_label = \"UTM Easting [km]\"\n",
    "    p[0][2].yaxis.axis_label = \"UTM Northing [km]\"\n",
    "    p[0][2].xaxis.axis_label_text_font_style = \"bold\"\n",
    "    p[0][2].yaxis.axis_label_text_font_style = \"bold\"\n",
    "    p[0][2].xaxis.major_label_text_font_style = \"bold\"\n",
    "    p[0][2].yaxis.major_label_text_font_style = \"bold\"\n",
    "    p[0][2].title.text_font_size = \"10pt\"\n",
    "    p[0][2].xaxis.axis_label_text_font_size = \"12pt\"\n",
    "    p[0][2].yaxis.axis_label_text_font_size = \"12pt\"\n",
    "    #p[0][2].patches(xs, ys, fill_alpha=0, line_width=3, line_color=\"orange\")\n",
    "\n",
    "    ####\n",
    "    if False:\n",
    "        shp_path = \"/home/jens/daten/BW_temperatureLogs_shallow/geometries/Verw-Grenzen_ALKIS/Verwaltungsgrenzen_NOrA_Dez_2022_ALKIS-Shape/v_al_land.shp\"\n",
    "        gdf = gpd.read_file(shp_path)\n",
    "    \n",
    "        # Sicherstellen, dass das CRS stimmt (EPSG:25832 - ETRS89 / UTM zone 32N)\n",
    "        #if gdf.crs != \"EPSG:25832\":\n",
    "        #    gdf = gdf.to_crs(\"EPSG:25832\")\n",
    "        \n",
    "        # --- Shapefile-Geometrien extrahieren und umrechnen (auf km und mit Offset) ---\n",
    "        xs = []\n",
    "        ys = []\n",
    "        for geom in gdf.geometry:\n",
    "            if geom.geom_type == 'Polygon':\n",
    "                x, y = geom.exterior.coords.xy\n",
    "                xs.append([(xi - x_offset) / 1000 for xi in x])\n",
    "                ys.append([(yi - y_offset) / 1000 for yi in y])\n",
    "            elif geom.geom_type == 'MultiPolygon':\n",
    "                for poly in geom.geoms:\n",
    "                    x, y = poly.exterior.coords.xy\n",
    "                    xs.append([(xi - x_offset) / 1000 for xi in x])\n",
    "                    ys.append([(yi - y_offset) / 1000 for yi in y])\n",
    "\n",
    "        line_color='green'\n",
    "    \n",
    "        p[0][0].patches(xs, ys, fill_alpha=0, line_width=3, line_color=line_color)\n",
    "        p[0][1].patches(xs, ys, fill_alpha=0, line_width=3, line_color=line_color)\n",
    "        if grid_drift is not None:\n",
    "            p[1][0].patches(xs, ys, fill_alpha=0, line_width=3, line_color=line_color)\n",
    "            p[1][1].patches(xs, ys, fill_alpha=0, line_width=3, line_color=line_color)\n",
    "\n",
    "    line_color='green'\n",
    "    \n",
    "    for region in regions_main:\n",
    "        path_shapefile = '/home/jens/daten/geometries/geological_regions/BW/auswertungsregionen'\n",
    "        shapefile = 'region_{}.shp'.format(region)\n",
    "\n",
    "        gdf = gpd.read_file(regions_path + '/' + shapefile)\n",
    "\n",
    "        if gdf.crs is None:\n",
    "            gdf.set_crs(epsg=4326, inplace=True)  # WGS84 setzen\n",
    "\n",
    "        # Reprojektion auf UTM Zone 32N (ETRS89)\n",
    "        if gdf.crs.to_epsg() != 25832:\n",
    "            gdf = gdf.to_crs(epsg=25832)\n",
    "        # --- Shapefile-Geometrien extrahieren und umrechnen (auf km und mit Offset) ---\n",
    "        xs = []\n",
    "        ys = []\n",
    "        for geom in gdf.geometry:\n",
    "            if geom.geom_type == 'Polygon':\n",
    "                x, y = geom.exterior.coords.xy\n",
    "                xs.append([(xi - x_offset) / 1000 for xi in x])\n",
    "                ys.append([(yi - y_offset) / 1000 for yi in y])\n",
    "            elif geom.geom_type == 'MultiPolygon':\n",
    "                for poly in geom.geoms:\n",
    "                    x, y = poly.exterior.coords.xy\n",
    "                    xs.append([(xi - x_offset) / 1000 for xi in x])\n",
    "                    ys.append([(yi - y_offset) / 1000 for yi in y])\n",
    "\n",
    "        p[0][0].patches(xs, ys, fill_alpha=0, line_width=2, line_color=line_color)\n",
    "        p[0][1].patches(xs, ys, fill_alpha=0, line_width=2, line_color=line_color)\n",
    "        if grid_drift is not None:\n",
    "            p[1][0].patches(xs, ys, fill_alpha=0, line_width=2, line_color=line_color)\n",
    "            p[1][1].patches(xs, ys, fill_alpha=0, line_width=2, line_color=line_color)\n",
    "\n",
    "    grid = gridplot(p) \n",
    "    show(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585385c4-707e-46a7-b013-ad6cd0c1efe9",
   "metadata": {},
   "source": [
    "<h1> Data preparation </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aede70-af7a-496e-9b3d-86a996fcc0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bhs_val = df_filt[f\"T_{T_selected}\"].to_numpy()\n",
    "bhs_coords = df_filt[['utm_easting','utm_northing']].to_numpy()\n",
    "bhs_elev = df_filt[\"elevation\"].to_numpy()\n",
    "\n",
    "bhs_x, bhs_y = bhs_coords[:,0], bhs_coords[:,1]\n",
    "\n",
    "bhs_val_cleaned = df_filt_cleaned[f\"T_{T_selected}\"].to_numpy()\n",
    "bhs_coords_cleaned = df_filt_cleaned[['utm_easting','utm_northing']].to_numpy()\n",
    "bhs_elev_cleaned = df_filt_cleaned[\"elevation\"].to_numpy()\n",
    "\n",
    "bhs_x_cleaned, bhs_y_cleaned = bhs_coords_cleaned[:,0], bhs_coords_cleaned[:,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1d360a-e18d-411a-8c67-94c25d8664ac",
   "metadata": {},
   "source": [
    "<h1> Variogram </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5ffbb0-910b-42f8-81ba-4724ccd1b8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleSpherical(gs.CovModel):\n",
    "    def __init__(self, dim=2, var1=1.0, len1=10_000,\n",
    "                 var2=2.0, len2=60_000, nugget=0.0):\n",
    "        # wir definieren \"var\" nur als Summe für GSTools-Interna\n",
    "        super().__init__(dim=dim, var=var1+var2, len_scale=max(len1, len2), nugget=nugget)\n",
    "        self.var1, self.len1 = var1, len1\n",
    "        self.var2, self.len2 = var2, len2\n",
    "        self.nugget_val = nugget\n",
    "\n",
    "    def variogram(self, r):\n",
    "        \"\"\"doppeltes sphärisches Variogramm\"\"\"\n",
    "        def spherical(h, var, rng):\n",
    "            h = np.asarray(h)\n",
    "            gamma = np.where(\n",
    "                h < rng,\n",
    "                var * (1.5*(h/rng) - 0.5*(h/rng)**3),\n",
    "                var\n",
    "            )\n",
    "            return gamma\n",
    "\n",
    "        gamma1 = spherical(r, self.var1, self.len1)\n",
    "        gamma2 = spherical(r, self.var2, self.len2)\n",
    "        return self.nugget_val + gamma1 + gamma2\n",
    "\n",
    "# --- Fit-Funktion für curve_fit ---\n",
    "def double_spherical_func(r, var1, len1, var2, len2, nugget):\n",
    "    model = DoubleSpherical(var1=var1, len1=len1,\n",
    "                            var2=var2, len2=len2,\n",
    "                            nugget=nugget)\n",
    "    return model.variogram(r)\n",
    "\n",
    "def spherical_func(r, var1, len1, nugget):\n",
    "    model = DoubleSpherical(var1=var1, len1=len1,\n",
    "                            var2=0., len2=0.,\n",
    "                            nugget=nugget)\n",
    "    return model.variogram(r)\n",
    "\n",
    "    \n",
    "\n",
    "def do_fit(func, bin_center, gamma, bin_counts, weighting=False):\n",
    "    sigma = 1.0 / np.sqrt(bin_counts)\n",
    "\n",
    "    if func == spherical_func:\n",
    "        p0 = [2.0, 30_000, .0]\n",
    "        bounds = ([0, 1000, 0], [10, 200_000, 2.])\n",
    "        if weighting:\n",
    "            popt, pcov = curve_fit(func, bin_center, gamma, p0=p0, bounds=bounds, sigma=sigma)\n",
    "        else:\n",
    "             popt, pcov = curve_fit(func, bin_center, gamma, p0=p0, bounds=bounds)           \n",
    "        var1_fit, len1_fit, nugget_fit = popt\n",
    "        var2_fit, len2_fit = 0., 0.\n",
    "    elif func == double_spherical_func:\n",
    "        p0 = [1.0, 10_000, 1.0, 20_000, 0.]\n",
    "        bounds = ([0, 1000, 0, 0, 0], [10, 200_000, 10, 200_000, 5])\n",
    "        if weighting:\n",
    "            popt, pcov = curve_fit(func, bin_center, gamma, p0=p0, bounds=bounds, sigma=sigma)\n",
    "        else:\n",
    "            popt, pcov = curve_fit(func, bin_center, gamma, p0=p0, bounds=bounds)            \n",
    "        var1_fit, len1_fit, var2_fit, len2_fit, nugget_fit = popt\n",
    "    else:\n",
    "        print(\"function not supported\")\n",
    "        return  0., 0., 0., 0., 0.\n",
    "\n",
    "    return var1_fit, len1_fit, var2_fit, len2_fit, nugget_fit\n",
    "\n",
    "def do_variogram_plot(fit_model, bin_center, gamma, bin_counts):\n",
    "    \n",
    "    gamma_pred = fit_model.variogram(bin_center)\n",
    "    r2 = r2_score(gamma, gamma_pred)\n",
    "    print(f\"R² = {r2:.3f}\")\n",
    "    \n",
    "    weights = bin_counts / np.sum(bin_counts)\n",
    "    ss_res = np.sum(weights * (gamma - gamma_pred)**2)\n",
    "    ss_tot = np.sum(weights * (gamma - np.average(gamma, weights=weights))**2)\n",
    "    r2_weighted = 1 - ss_res/ss_tot\n",
    "    print(f\"R² weighted = {r2_weighted:.3f}\")\n",
    "    \n",
    "    para = {}\n",
    "    para['var1'] = fit_model.var1\n",
    "    para['var2'] = fit_model.var2\n",
    "    para['len_scale1'] = fit_model.len1\n",
    "    para['len_scale2'] = fit_model.len2\n",
    "    para['nugget'] = fit_model.nugget\n",
    "    \n",
    "    plot_variogram(\"Fitted DoubleSpherical\", fit_model, bin_center, gamma, bin_counts, para, r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68564e5a-20f8-43f8-9023-463f66caa0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Empirisches Variogramm ---\n",
    "bin_center, gamma, bin_counts = gs.vario_estimate(\n",
    "    (bhs_x_cleaned, bhs_y_cleaned),\n",
    "    bhs_val_cleaned,\n",
    "    return_counts=True\n",
    ")\n",
    "\n",
    "var1_fit, len1_fit, var2_fit, len2_fit, nugget_fit = do_fit(\n",
    "    spherical_func, \n",
    "    #double_spherical_func,\n",
    "    bin_center, gamma, bin_counts, #weighting=True\n",
    ")\n",
    "\n",
    "print(\"Gefundene Parameter:\")\n",
    "print(f\"var1={var1_fit:.3f}, len1={len1_fit:.0f}, var2={var2_fit:.3f}, len2={len2_fit:.0f}, nugget={nugget_fit:.3f}\")\n",
    "\n",
    "if dataset == 'RLP':\n",
    "    nugget_fit = 1\n",
    "    var1_fit = 2.1\n",
    "    len1_fit = 25000\n",
    "elif dataset == 'BW':\n",
    "    len1_fit = 25000\n",
    "    \n",
    "print(\"Gesetzte Parameter:\")\n",
    "print(f\"var1={var1_fit:.3f}, len1={len1_fit:.0f}, var2={var2_fit:.3f}, len2={len2_fit:.0f}, nugget={nugget_fit:.3f}\")\n",
    "\n",
    "# --- Modell mit Fit-Parametern ---\n",
    "fit_model_global = DoubleSpherical(var1=var1_fit, len1=len1_fit,\n",
    "                            var2=var2_fit, len2=len2_fit,\n",
    "                            nugget=nugget_fit)\n",
    "\n",
    "#do_variogram_plot(fit_model_global, bin_center, gamma, bin_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f0e483-1602-436c-95fb-2fcd9566d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if logarithmic:\n",
    "    residual = np.log(bhs_val_cleaned) - trend_global(df_filt_cleaned[\"elevation\"], df_filt_cleaned[sealing_selected])\n",
    "else:\n",
    "    residual = bhs_val_cleaned - trend_global(df_filt_cleaned[\"elevation\"], df_filt_cleaned[sealing_selected])\n",
    "\n",
    "# --- Empirisches Variogramm ---\n",
    "bin_center, gamma, bin_counts = gs.vario_estimate(\n",
    "    (bhs_x_cleaned, bhs_y_cleaned),\n",
    "    residual,\n",
    "    return_counts=True\n",
    ")\n",
    "\n",
    "var1_fit, len1_fit, var2_fit, len2_fit, nugget_fit = do_fit(\n",
    "    spherical_func, \n",
    "    #double_spherical_func,\n",
    "    bin_center, gamma, bin_counts, #weighting=True\n",
    ")\n",
    "\n",
    "print(\"Gefundene Parameter:\")\n",
    "print(f\"var1={var1_fit:.3f}, len1={len1_fit:.0f}, var2={var2_fit:.3f}, len2={len2_fit:.0f}, nugget={nugget_fit:.3f}\")\n",
    "\n",
    "if dataset == 'RLP':\n",
    "    #nugget_fit = 0\n",
    "    #var1_fit = 1.8\n",
    "    len1_fit = 25000\n",
    "elif dataset == 'BW':\n",
    "    len1_fit = 25000\n",
    "\n",
    "print(\"Gesetzte Parameter:\")\n",
    "print(f\"var1={var1_fit:.3f}, len1={len1_fit:.0f}, var2={var2_fit:.3f}, len2={len2_fit:.0f}, nugget={nugget_fit:.3f}\")\n",
    "\n",
    "    \n",
    "# --- Modell mit Fit-Parametern ---\n",
    "fit_model_global_res = DoubleSpherical(var1=var1_fit, len1=len1_fit,\n",
    "                            var2=var2_fit, len2=len2_fit,\n",
    "                            nugget=nugget_fit)\n",
    "\n",
    "#do_variogram_plot(fit_model_global_res, bin_center, gamma, bin_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a2aeee-4f2f-4e42-afa6-a7f8994e3554",
   "metadata": {},
   "source": [
    "<h1> Kriging </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f34670f-063f-4fae-93b1-a233b160a96a",
   "metadata": {},
   "source": [
    "<h2> Ordinary </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe74653-722a-4b4e-9350-f0ff298075f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "krig = gs.krige.Ordinary(model=fit_model_global, cond_pos=(bhs_x,bhs_y), cond_val=bhs_val, #unbiased=True\n",
    "               )\n",
    "\n",
    "\n",
    "srf, var = krig.structured([gridx, gridy])\n",
    "\n",
    "do_bplot('Ordinary', dem_file, [0, 1000], [gridx, gridy],\n",
    "         srf, var, df_filt, df_filt_cleaned, bhs_x, bhs_y, bhs_val, grid_drift=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a778737a-e1d3-4343-b345-8be6cc2bb392",
   "metadata": {},
   "source": [
    "<h2> Global residual </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c856f4a1-1410-4ac2-b276-176d3ecb9e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if logarithmic:\n",
    "    residual = np.log(bhs_val) - trend_global(df_filt[\"elevation\"], df_filt[sealing_selected])\n",
    "else:\n",
    "    residual = bhs_val - trend_global(df_filt[\"elevation\"], df_filt[sealing_selected])\n",
    "    \n",
    "# Residuen krigen (OK mit Mittelwert unbekannt—bei residuen oft ~0; SK mit mean=0 geht auch)\n",
    "ok = gs.krige.Ordinary(\n",
    "    model=fit_model_global_res,\n",
    "    cond_pos=(bhs_x, bhs_y),\n",
    "    cond_val=residual\n",
    ")\n",
    "\n",
    "# Residualfeld auf Grid\n",
    "r_srf, r_var = ok.structured([gridx, gridy])\n",
    "\n",
    "grid_drift = trend_global(grid_elevation_values, grid_sealing_values)\n",
    "\n",
    "srf = r_srf + grid_drift\n",
    "\n",
    "\n",
    "do_bplot('Global res', dem_file, [0, 1000], [gridx, gridy], srf, \n",
    "         r_var, df_filt, df_filt_cleaned, bhs_x, bhs_y, bhs_val, grid_drift=grid_drift, logarithmic=logarithmic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fd9a97-a3d1-405a-b8b5-9869506fdaef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037b204e-a609-40a0-883c-efb89b9e31ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12- kriging",
   "language": "python",
   "name": "kriging"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
